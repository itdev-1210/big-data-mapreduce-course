export SPARK_HOME="/home/mparsian/spark-2.3.0"
export INPUT_FILE="/home/mparsian/code/sample_file.txt"
export SPARK_PROG="/home/mparsian/code/word_count_driver.py"
#
# run the PySpark program:
$SPARK_HOME/bin/spark-submit $SPARK_PROG $INPUT_FILE

./bin/spark-submit word_count_driver.py sample_file.txt

input_path: sample_file.txt

records.count():  3

records.collect():  
[
 u'red fox jumped high and high', 
 u'red fox jumped high fence', 
 u'fox jumped'
]

non_empty_records.count():  3

non_empty_records.collect():  
[
 u'red fox jumped high and high', 
 u'red fox jumped high fence', 
 u'fox jumped'
]

words.count():  13

words.collect():  
[
 u'red', 
 u'fox', 
 u'jumped', 
 u'high', 
 u'and', 
 u'high', 
 u'red', 
 u'fox', 
 u'jumped', 
 u'high', 
 u'fence', 
 u'fox', 
 u'jumped'
]

pairs.count():  13

pairs.collect():  
[
 (u'red', 1), 
 (u'fox', 1), 
 (u'jumped', 1), 
 (u'high', 1), 
 (u'and', 1), 
 (u'high', 1), 
 (u'red', 1), 
 (u'fox', 1), 
 (u'jumped', 1), 
 (u'high', 1), 
 (u'fence', 1), 
 (u'fox', 1), 
 (u'jumped', 1)
]

frequencies.count():  6

frequencies.collect():  
[
 (u'and', 1), 
 (u'high', 3), 
 (u'fox', 3), 
 (u'red', 2), 
 (u'fence', 1), 
 (u'jumped', 3)
]